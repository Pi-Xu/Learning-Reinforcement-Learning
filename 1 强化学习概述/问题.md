## 问题汇总

1. 对于policy而言, 如何估计$\pi(a \mid s) = p(a_t = a \mid s_t = s)$
2. 对于$V_\pi(s) = E_\pi[\sum_{k=0}^{\infty} \gamma^k r_{t+k+1} \mid s_t = s]$, 中Reward的函数应该如何计算, 是否已经涉及到未来的状态($s_{t+1}$等信息)
3. Q函数的理解: $Q_\pi(a, s)=E_\pi[\sum_{k=0}^{\infty}\gamma ^k r_{t+k+1} \mid s_t = s, a_t = a]$, 主要问题在于如何理解其中的随机变量
   1. R函数已知, 可以写作未来的s和a的函数
   2. $\pi$是关于$a$的函数, 即a的条件概率密度函数
   3. 主要是对**未来的状态和动作**的一种不确定性所产生的随机变量, 所以能够求期望(积分), **详见CS285课程**

## 问题解决

TODO: 更新cs285(UC Berkeley)的notes中对$\pi$和$a, s$等的定义的参考
