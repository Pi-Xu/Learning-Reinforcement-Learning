# 重要公式推导

## 基本定义

该部分的主要思路是使用Q函数来学习策略的, 中间使用了最优贝尔曼方程等公理进行计算.

1. 最优动作价值函数(通过*最优贝尔曼方程*)

$$
Q_\pi (s_t, a_t) = \mathbb{E}[U_t \mid S_t = s_t, A_t = a_t]\\
Q_*(s_t, a_t) = \max_\pi Q_\pi(s_t, a_t)
$$

所需要的便是下面的$Q_*$函数

2. 如何求解这个动作价值函数

$$
\underbrace{Q_{\star}\left(s_{t}, a_{t}\right)}_{U_{t} \text { 的期望 }}=\mathbb{E}_{S_{t+1} \sim p\left(\cdot \mid s_{t}, a_{t}\right)}[R_{t}+\gamma \cdot \underbrace{\max _{A \in \mathcal{A}} Q_{\star}\left(S_{t+1}, A\right)}_{U_{t+1} \text { 的期望 }} \mid S_{t}=s_{t}, A_{t}=a_{t}]
$$

使用MC方法近似后可得:

$$
Q_{\star}\left(s_{t}, a_{t}\right) \approx r_{t}+\gamma \cdot \max _{a \in \mathcal{A}} Q_{\star}\left(s_{t+1}, a\right)
$$

替换为DNN表示方法可得:

$$
\underbrace{Q\left(s_{t}, a_{t} ; \boldsymbol{w}\right)}_{\text {预测 } \widehat{q_{t}}} \approx \underbrace{r_{t}+\gamma \cdot \max _{a \in \mathcal{A}} Q\left(s_{t+1}, a ; \boldsymbol{w}\right)}_{\text {TD 目标 } \widehat{y}_{t}} .
$$

3. 与TD方法的联系

TD算法中的梯度为:

$$
\nabla_{\boldsymbol{w}} L(\boldsymbol{w})=\underbrace{\left(\widehat{q_{t}}-\widehat{y}_{t}\right)}_{\mathrm{TD} \text { 误差 } \delta_{t}} \cdot \nabla_{\boldsymbol{w}} Q\left(s_{t}, a_{t} ; \boldsymbol{w}\right)
$$

### 使用TD求解的流程

- 收集训练数据
  - 经验回放数组 (Replay Buffer), 以如下方式收集并存放之

$$
a_{t}=\left\{\begin{array}{ll}
\operatorname{argmax}_{a} Q\left(s_{t}, a ; \boldsymbol{w}\right), & \text { 以概率 }(1-\epsilon) ; \\
\text { 均匀抽取 } \mathcal{A} \text { 中的一个动作, } & \text { 以概率 } \epsilon .
\end{array}\right.
$$

- 更新DQN参数

1. 正向传播

$$
\widehat{q}_{j}=Q\left(s_{j}, a_{j} ; \boldsymbol{w}_{\text {now }}\right) \quad \text { 和 } \quad \widehat{q}_{j+1}=\max _{a \in \mathcal{A}} Q\left(s_{j+1}, a ; \boldsymbol{w}_{\text {now }}\right) 
$$

2. 计算TD Target与TD Error

$$
\widehat{y}_{j}=r_{j}+\gamma \cdot \widehat{q}_{j+1} \quad \text { 和 } \quad \delta_{j}=\widehat{q}_{j}-\widehat{y}_{j} 
$$

3. 反向传播与梯度

$$
\boldsymbol{g}_{j}=\nabla_{\boldsymbol{w}} Q\left(s_{j}, a_{j} ; \boldsymbol{w}_{\mathrm{now}}\right)
$$

4. 梯度下降并更新

$$
\boldsymbol{w}_{\text {new }} \leftarrow \boldsymbol{w}_{\text {now }}-\alpha \cdot \delta_{j} \cdot \boldsymbol{g}_{j}
$$

## DQN 高级技巧
